[{"content":"CUDA简明介绍 随着AI的兴起，老黄的计算卡一卡难求，在深度学习领域老黄已经几乎事实上达到了垄断的地位。而让老黄成为AI领域那个“卖铲子”的正是CUDA，或者说是围绕CUDA诞生的一系列软件生态。\n今天就用CUDA实现一个矩阵乘法来简单介绍一下CUDA是如何让GPU突破摩尔定律的以及为什么在AI训练中是如此重要。\nCUDA是什么 CUDA全称Compute Unified Device Architecture，是老黄推出的API，方便开发者调用NVIDIA GPU用来进行大规模并行计算。\n老黄在Clang编译器的基础上拓展开发了针对CUDA的编译器NVCC，所以NVCC支持大部分C/C++语法特性同时支持针对CUDA的拓展语法。\n如何搭建CUDA编程环境 由于NVIDIA与开源社区一向水火不容，所以导致N卡在Linux的兼容性不说完美无缺至少也是丝毫没有，当然这两年由于NVIDIA的数据中心业务水涨船高，老黄也逐渐开源了部分GPU驱动相比于以前已经是好很多了。但是目前来说体验最好的还是用wsl2搭配vscode，不需要折腾驱动，几乎是一键安装，同时NVIDIA也提供了docker镜像方便部署维护，具体可以看上一篇配置wsl2的文章。\nCUDA实现矩阵乘法 计算机架构 计算流程 在使用CUDA编程前，我们需要对计算机架构需要有一个了解。\n一般来说计算机计算，遵循如下流程 但是当GPU加入进来后的异构计算流程则有一定的区别 在程序运行过程中可以理解为CPU与GPU是异步的，两者通过PCIE通道通信，CPU调用kernel函数后后并不会等待GPU计算结束再继续而是直接继续运行。\nGPU架构 我们这里简单介绍一下GPU的架构，上图是H100的架构图。整个H100有8组GPC，每组GPC有9组TPC，每组TPC又有两组SM，而每组SM又有144个CUDA Tensor，共有18432个CUDA Tensor以及两组24MB的L2缓存。同时由于H100是计算专用卡，所以老黄只留了一组光栅单元，打游戏是基本没戏了。\n这里每个CUDA Tensor都可以看成是一个CPU核心，但是相比于CPU核心CUDA Tensor不能做复杂的逻辑运算，适合做大规模的并行计算，尤其是适合做矩阵运算。\n代码实现 我这里使用CUDA C/C++来实现矩阵的乘法。\n1 2 #define MATRIX_SIZE_ROW 32 #define MATRIX_SIZE_COL 32 我们首先定义一下矩阵的大小。\n接着用malloc分配一下内存以及利用随机函数给矩阵赋值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 float *a, *b, *c; // Host matrices a = (float *)malloc(sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW); b = (float *)malloc(sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW); c = (float *)malloc(sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW); FILE *filea = fopen(\u0026#34;matrix_a.txt\u0026#34;, \u0026#34;w\u0026#34;); FILE *fileb = fopen(\u0026#34;matrix_b.txt\u0026#34;, \u0026#34;w\u0026#34;); for (int i = 0; i \u0026lt; MATRIX_SIZE_ROW * MATRIX_SIZE_COL; ++i) { a[i] = (float)(rand() % 10); b[i] = (float)(rand() % 10); fprintf(filea, \u0026#34;%lf \u0026#34;, a[i]); fprintf(fileb, \u0026#34;%lf \u0026#34;, b[i]); if (i % MATRIX_SIZE_COL == 0 \u0026amp;\u0026amp; i!=0) { fprintf(filea, \u0026#34;\\n\u0026#34;); fprintf(fileb, \u0026#34;\\n\u0026#34;); } } 这里我把矩阵数值保存到文本中，方便查看。\n由于我们需要将host即主机上的数据复制到device即GPU上，所以我们也需要在GPU上分配内存\n1 2 3 4 5 6 7 8 float *dev_a, *dev_b, *dev_c; // Device matrices // Allocate memory for device matrices cudaMalloc((void **)\u0026amp;dev_a, sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW); cudaMalloc((void **)\u0026amp;dev_b, sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW); cudaMalloc((void **)\u0026amp;dev_c, sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW); // Copy host matrices to device matrices cudaMemcpy(dev_a, a, sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW, cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW, cudaMemcpyHostToDevice); 这里用到了CUDA C/C++两个API\ncudaMalloc用来在GPU上分配内存cudaMalloc(*ptr,size) cudaMemcpy用来将host上的内存数据复制到device中 接着我们就需要写kernel函数了，即在device上运行的函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // CUDA kernel function to multiply matrices __global__ void matrixMul(float *a, float *b, float *c, int matrix_size_row, int matrix_size_col) { int row = threadIdx.y + blockIdx.y * blockDim.y; int col = threadIdx.x + blockIdx.x * blockDim.x; if (row \u0026lt; matrix_size_row \u0026amp;\u0026amp; col \u0026lt; matrix_size_col) { float sum = 0.0f; for (int i = 0; i \u0026lt; matrix_size_col; ++i) { sum += a[row * matrix_size_col + i] * b[i * matrix_size_col+ col]; } c[row * matrix_size_col + col] = sum; } } 这里有几个要点\n这里的__global__是CUDA C/C++的拓展语法，表明函数是在GPU上执行的，相对的还有__host__和__device__关键词，分别表CPU调用函数(这里__host__一般不显示声明)以及在__global__函数中调用host函数。 重要的一点所有的kernel函数都必须要用void即没有返回值。 与常规的计算流程不同，CUDA并行计算是将对矩阵的索引变为对CUDA线程的索引，这极大的加速了矩阵的计算。 接着我们需要为kernel函数手动分配线程数\n1 2 3 4 5 dim3 blockDim(MATRIX_SIZE_COL, MATRIX_SIZE_ROW); dim3 gridDim((MATRIX_SIZE_COL + blockDim.x - 1) / blockDim.x, (MATRIX_SIZE_ROW + blockDim.y - 1) / blockDim.y); // Launch kernel to multiply matrices matrixMul\u0026lt;\u0026lt;\u0026lt;gridDim, blockDim\u0026gt;\u0026gt;\u0026gt;(dev_a, dev_b, dev_c, MATRIX_SIZE_ROW, MATRIX_SIZE_COL); 这里同样用到了拓展语法分别是dim3数据类型以及\u0026lt;\u0026lt;\u0026lt;gridDim, blockDim\u0026gt;\u0026gt;\u0026gt;\ndim3是用来保存分配线程数的数据类型，这里要简单介绍一下CUDA的线程概念，分别是grid、block以及thread，每个grid中可以包含$N_x \\times N_y \\times N_z$个block同样每个block也可以包含$X \\times Y \\times Z$个线程，这样我们需要对每个线程进行索引，简单来说就可以想象成将一个二维的矩阵映射到一维进行索引。同时也要注意，在进行索引时不能超出所分配的线程数，否则会发生越界。 \u0026lt;\u0026lt;\u0026lt;gridDim, blockDim\u0026gt;\u0026gt;\u0026gt;这个拓展语法则相对好理解的多，即对matrixMul这个函数分配了对应的线程数。 最后当GPU计算完成，我们还需要将GPU的计算结果同步到CPU中（养成释放内存的好习惯\n1 2 3 4 5 6 7 8 cudaMemcpy(c, dev_c, sizeof(float) * MATRIX_SIZE_COL * MATRIX_SIZE_ROW, cudaMemcpyDeviceToHost); free(a); free(b); free(c); cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_c); 这里同样是利用cudaMemcpy这个函数，将device的数据复制到host中，这里并没有显示的用cudaDeviceSynchronize这个API让CPU等待GPU计算完成再计算，cudaMemcpy隐含了同步的操作。\n至此我们已经完成了利用CUDA实现矩阵乘法的流程。如果想看完整代码可以移步我的代码仓库 总结 利用CUDA编程的整体思路还是想当固定的，即为device分配内存，将host数据拷贝到device中，device计算，完成后将device计算结果拷贝到host，最后释放内存。\n当然本文写的也是相当简化的一个步骤，CUDA编程相当复杂涉及到很多计算机架构和GPU硬件的知识，比如在涉及到需要经常读取的数据我们就需要用__share__关键词将数据存储到GPU的共享内存，同样在并行求和时常用的reduce算法涉及到数据在线程与线程间归并以及数据竞争的问题。\nCUDA编程相较于传统CPU的串行计算有很大的不同，需要我们用不同的视角看问题，同时看到利用CUDA进行并行计算获得远超CPU串行计算的性能时，获得的成就感还是相当让人兴奋的。\n","date":"2024-03-31T11:45:36+08:00","image":"https://raw.githubusercontent.com/xbunax/blogImg/main/202403311231061.webp","permalink":"http://localhost:1313/p/cuda%E7%AE%80%E6%98%8E%E4%BB%8B%E7%BB%8D/","title":"CUDA简明介绍"},{"content":"微软在拥抱开源社区后推出wsl极大提升了Windows的开发体验，相比双系统wsl可以动态分配存储空间和内存，并且搭配vscode可以获得几乎原生Linux的开发体验。\n在微软更新wsl2之后，现在可以与Windows宿主机共用host，不同再去获取wsl2的动态IP，每次都要手动设置代理，更加方便开发了。\n本篇博文主要是记录一下在wsl2中配置深度学习环境。\nInstall wsl2 要安装wsl2首先要在系统服务中打开hyper-V虚拟化以及Linux sub system。 在Windows应用商店中搜索Ubuntu直接安装就可以了。 因为wsl2默认安装在C盘，所以可以在poweshell中用wsl命令将Linux子系统打包成tar或者镜像文件，然后export到另外的分区中。 Config wsl2 首先启动需要设置好username和passwd\n我个人使用zsh搭配oh my zsh美化比较多。可以使用apt安装\n1 2 3 sudo apt update sudo apt install zsh sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 接下来安装深度学习必备的python环境，anaconda作为python的环境管理有点太重了，推荐使用miniconda 1 2 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh 如果要使用GPU加速，还需要安装CUDA-TOOlkit以及NVIDIA Driver，这部分工具链已经很完善了，微软也提供了完善的官方文档。\n1.首先安装NVIDIA Driver，这个可以直接在NVIDIA官网上找到，安装与自己GPU型号对应的驱动即可\nTIPS: 安装的时候选择Windows版驱动即可。\n2.接着安装CUDA支持\n1 2 3 4 5 6 7 8 9 sudo apt-key del 7fa2af80 #去除旧的GPG key wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600 wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb sudo dpkg -i cuda-repo-wsl-ubuntu-12-4-local_12.4.0-1_amd64.deb sudo cp /var/cuda-repo-wsl-ubuntu-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/ sudo apt-get update sudo apt-get -y install cuda-toolkit-12-4 3.确认安装是否完成\n1 2 nvcc -v #查看nvcc编译器是否安装 nvidia-smi #查看gpu状态 接下来安装一下pytorch，即\n1 conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia # 这里使用cuda12.1 安装完成后可以在python中用torch.cuda.is_available()查看是否可以调用GPU加速。\n","date":"2024-03-24T11:37:50+08:00","image":"https://raw.githubusercontent.com/xbunax/blogImg/main/202403241154248.webp","permalink":"http://localhost:1313/p/configwsl/","title":"Configwsl"},{"content":"对于使用Spotify作为主力音乐流媒体的人来说，Spotify官方的桌面app体验并不是很好，无法看歌词，而且UI水平对于我个人审美来说感觉并不是很好看。\nSpotify 第三方客户端 Spotify webUI 这时候就要选择第三方的Spotify客户端了，或者也可以使用Spotify的webUI然后使用美化插件，我webUI使用的Arc浏览器搭配上Gallery美化，其实最后的效果还可以，而且很轻量化，除了没法看歌词都很完美。\nSpotify TUI 但是webUI到底还是官方的UI而且没法看歌词，而且作为重度终端使用者，还是希望在终端上使用Spotify。我选择使用的是spotify_player一个用rust开发的开源的Spotify TUI，使用vim的键位并且在iTerm2中可以显示专辑封面，同时也可以在配置文件~/.config/spotify-player/app.toml中进行自定义。\nSpotify Lyrics 接下来要解决官方客户端无法看歌词的问题，我们可以使用sptlrx这个开源的终端歌词同步软件，搭配spotify_player使用可以看当前歌曲的歌词。\nCustom Your TUI 这样我们就实现了在终端上使用Spotify并且显示滚动歌词，同时搭配cava(一个Audio Visualizer，依赖backgroud Music实现)，最后使用tty-clock为整个布局点缀一下，就可以实现封面的效果了。\nOptimization 虽然这样布局很不错，但是每次都要手动分屏很麻烦，能不能实现在终端敲一个命令自动分屏布局并且每个pane自动执行对应的命令呢，当然是可以的啦。\n我一开始选择使用tmux和tmuxp这样就可以用yml配置文件写好tmux session布局并且在对应的pane执行不同的命令，但是研究了一下tmuxp发现好像无法实现封面那样的复杂布局，只有几个预设的布局，而且tmux无法显示超过1M大小的图片所以spotify_player无法显示图片。\n所以最后另辟蹊径，使用AppleScript直接对iTerm2进行布局。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 tell application \u0026#34;iTerm\u0026#34; tell current window tell current session of current tab split vertically with default profile split vertically with default profile end tell tell third session of current tab split horizontally with default profile end tell tell first session of current tab write text \u0026#34;spotify_player\u0026#34; end tell tell second session of current tab write text \u0026#34;sptlrx\u0026#34; end tell tell third session of current tab write text \u0026#34;tty-clock -c -s\u0026#34; end tell tell fourth session of current tab write text \u0026#34;cava\u0026#34; end tell end tell end tell 这样将AppleScript保存为scpt文件，只需要在终端中用osascript scpt文件路径执行AppleScript脚本就可以实现一键布局啦。如果嫌每次输osascript命令很麻烦，在~/.zshrc中用alias映射一下命令或者写个shell脚本添加到环境变量就可以啦。\n这就是最后的效果啦。\n如果要使用本教程需要会一点Unix-like系统的操作，最基础的ls cd这些需要会使用，如果是Mac则要安装Homebrew作为包管理器，方便管理和安装。 如果要使用spotify_player需要一个Spotify的会员账号，并且去dev spotify申请一个client id。 ","date":"2024-03-06T13:17:22+08:00","image":"https://raw.githubusercontent.com/xbunax/blogImg/main/spotify_tui/cover.png","permalink":"http://localhost:1313/p/spotify_tui/","title":"Spotify_tui"},{"content":" My Mac Workflow 作为一个六年的Mac用户，从2018款macbook pro到M2芯片的macbook air，积累了很多Mac的使用心得与好用的软件。在此分享一下我在Mac上的workflow。\nTips：本人专业背景为理论物理，主要科研工作偏向使用Unix-like系统，所以不会涉及windows(但是可以使用wsl2)。 推荐安装homebrew作为MacOS上的包管理器。 Zotero 作为科研狗第一重要的事当然是看文献了，那么一个好的文献管理器至关重要，虽然学校提供了正版的EndNote但是相比而言更喜欢免费的Zotero，并且可以安装第三方插件，例如我装了preview插件可以预览文献内容。 并且我主要使用latex为论文排版，Zotero可以快速导出bibtex文件方便在论文中引用文献。 同时Zotero可以利用官方提供的网盘进行多平台同步，但是免费容量只有5G，一般来说够用但是为了长远考虑，我使用微软学生认证提供的2T OneDrive挂载到koofr实现webDAV，这样就能使用白嫖到的2T空间做同步备份了。 Material Project 作为广大炼丹烧炉子研究工作者，在科研中肯定遇到要查询材料参数的情况，MaterialProject，这个网站作为材料领域做高通量计算方向搭建的，囊括了大量的材料参数，并且作为开源项目的一部分，此网站还提供了python的package(pymatgen)方便调用网站的api，可以获取材料的晶格结构等并且给出相关的文献。\nPngpaste 我的论文写作工具主要是neovim+latex，但是由于饱受latex上古语法困扰最近也在尝试typst并且得益于neovim活跃的社区，typst的lsp还有双向链接工具已经完全可用了。\n不管是latex还是typst写作时一直有一个痛点那就是插入图片，往往我会将图片截图存在剪贴板中，但是在用neovim写论文时，经常要切出去保存图片非常影响效率。这时候我们就可以用pngpaste这个CLI工具，可以在命令行环境下读取剪贴板图片保存为png格式，这样在neovim中用toggleterm插件写一个autocmd自动保存剪贴板图片，大大提升了效率。\nWindow Manager 由于苹果的封闭，Mac上的窗口管理器选择并不是很多，yabai虽然可以实现平铺窗口管理器的大部分功能，但是需要关闭SIP，无法在Mac上使用iPad和iPhone应用也无法使用Touch ID支付。博主本人尝试过后发现bug相对较多，而且yabai的主要贡献者只有作者一人，yabai调用的api非常底层，每次苹果更新系统过都要等待作者适配，就体验来说并不是很好。\n现在博主主力的window Manager是amethyst。相比于yabai的优势在于不用关闭SIP所以相对来说受系统版本变化影响较小，而且amethyst配置相对简单，基本等于开箱即用，设置好快捷键键位就可以用了，不需要像yabai设置好yabairc还需要利用skhd再去映射快捷键，虽然可以直接抄大佬的配置，但是需要踩的坑还是相对多一点。\n但是不需要关闭SIP，就意味着相较于yabai，amethyst相对而言还是缺少了类似于创建销毁窗口，设置windows animation全局窗口透明度这些功能。但是amethyst作为平铺窗口管理还是合格了，快速移动窗口，一键更改布局，单独设置float窗口.\n","date":"2024-03-05T17:13:34+08:00","image":"https://raw.githubusercontent.com/xbunax/blogImg/main/workflow/cover.png","permalink":"http://localhost:1313/p/mymacworkflow/","title":"MyMacWorkflow"},{"content":"Hello World ","date":"2024-02-25T13:36:38+08:00","permalink":"http://localhost:1313/p/first/","title":"First"}]